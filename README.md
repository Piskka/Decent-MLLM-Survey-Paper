# Survey on Multimodal Large Language Models (MLLMs) in Education

## Abstract
This survey paper explores the objectives, methods, and key findings related to the application of Multimodal Large Language Models (MLLMs) in education. We investigate how MLLMs, integrating various data modalities, enhance educational experiences across language learning, STEM education, interactive content creation and Medicine/Healthcare Education. Key findings highlight significant improvements in engagement and learning outcomes facilitated by MLLMs. Future directions suggest advancements in technology and personalised learning trends. This survey underscores the transformative potential of MLLMs in modern education and calls for further research and development.

## 1. Introduction

### Background[1,2,3,23]
The integration of technology in education has revolutionised the learning experience, offering tools and platforms that enhance accessibility, engagement, and understanding. From early computer-assisted learning to contemporary AI-driven educational applications, technology's role has been pivotal in transforming traditional educational paradigms.

### Introduction to MLLMs[13]
Multimodal Large Language Models (MLLMs) represent the latest advancement in AI technology, capable of processing and generating human-like text by integrating various data modalities such as text, images, and sounds. These models leverage large datasets and sophisticated neural networks to understand and produce contextually relevant content across different formats.

### Scope and Objectives[4,5,6]
This survey aims to provide a comprehensive overview of MLLMs, examining their components, technologies, and prominent examples. We delve into their applications in education, particularly in language learning, STEM education, and interactive content creation. The objective is to assess the current landscape, evaluate their effectiveness, and explore future opportunities for enhancing educational outcomes.

## 2. Overview of MLLMs

### Definition and Explanation[13,17,18]
Multimodal Large Language Models (MLLMs) are advanced AI systems designed to process and understand information across multiple modalities, including text, images, and audio. By integrating these diverse data types, MLLMs can generate more nuanced and contextually appropriate responses, making them valuable for a wide range of applications.

### Key Components and Technologies[13,28]
The core components of MLLMs include neural networks, particularly transformer architectures, which enable the processing and integration of multimodal data. Key technologies involve data integration techniques that allow these models to combine and interpret information from various sources, enhancing their overall understanding and output quality.

### Examples of Prominent MLLMs[13]
Several notable MLLMs have emerged, showcasing the potential of this technology:

- **CLIP (Contrastive Languageâ€“Image Pretraining)**: Developed by OpenAI, CLIP can understand and generate text based on image inputs, bridging the gap between visual and textual data.
- **DALL-E**: Another OpenAI creation, DALL-E generates images from textual descriptions, demonstrating the model's ability to integrate and produce multimodal content.
- **GPT-4**: The latest iteration of the Generative Pre-trained Transformer series, GPT-4 excels in text generation and understanding, incorporating multimodal capabilities to enhance its performance.

## 3. Applications of MLLMs in Education

## Language Learning[25,37]

MLLMs offer various applications in language learning, enhancing the interactive and immersive experience:

- **Interactive vocabulary learning:** Tools powered by MLLMs provide dynamic and contextual vocabulary exercises.
- **Pronunciation practice and feedback:** AI-driven applications offer real-time feedback on pronunciation, aiding in language acquisition.
- **AI-driven conversation practice:** MLLMs enable simulated conversation scenarios, providing learners with practice opportunities in real-world contexts.
- **Case study:** Duolingo's use of AI for rapid lesson generation demonstrates the efficiency and effectiveness of MLLM-powered content creation.
- **Evaluation:** Studies indicate significant improvements in learner outcomes when utilising MLLM-based tools compared to traditional methods.

## STEM Education (Science, Technology, Engineering, and Mathematics)[34]

MLLMs support various aspects of STEM education, offering innovative tools and simulations:

- **Virtual labs and simulations:** These models create interactive virtual labs, allowing students to conduct experiments in a safe and controlled environment.
- **Visualisation tools for mathematical concepts:** MLLMs help visualise complex mathematical concepts, making them easier to understand.
- **Case study:** The implementation of virtual labs in a high school physics curriculum has led to increased student comprehension and interest.
- **Evaluation:** Surveys indicate that students using MLLM-based STEM tools outperform their peers in traditional learning environments.

## Interactive Educational Content Creation

MLLMs facilitate the creation of multimodal educational materials, enriching the learning experience:

- **Tools for creating multimodal educational materials:** Platforms like H5P and Adobe Captivate leverage MLLMs to create engaging and interactive content.
- **Examples of authoring platforms:** H5P and Adobe Captivate are leading examples of how MLLMs are integrated into educational content creation.
- **Case study:** H5P has been effectively used to create interactive and multimedia-rich educational content, demonstrating the power of MLLMs in content creation.
- **Evaluation:** Feedback from educators and students highlights the increased engagement and retention rates when using multimodal educational materials.

## Medicine/Healthcare Education[7,8,9,10,21]

MLLMs are revolutionising medical education by providing advanced tools for learning and training:

- **Interactive case studies and simulations:** MLLMs can simulate patient cases and medical scenarios, providing students with hands-on experience in a virtual environment.
- **Diagnostic assistance:** AI-driven models assist in diagnosing medical conditions based on multimodal data, enhancing the learning experience for medical students.
- **Personalised learning paths:** MLLMs tailor educational content to the individual needs of medical students, helping them focus on areas where they need improvement.
- **Case study:** The integration of AI and multimodal language models in managing heart failure provides a detailed example of how these tools can be used in medical education.
- **Evaluation:** Studies show that medical students using MLLM-based educational tools demonstrate better diagnostic skills and a deeper understanding of complex medical concepts.

## 4. Future Directions and Opportunities

### Potential Advancements[29,30,31,32]
Advancements in MLLM technology hold promise for even greater impact in education:

- Improved integration of multimodal data for more accurate and context-aware outputs.
- Enhanced personalisation features, tailoring educational experiences to individual learner needs.

### Emerging Trends[16,18,27,28,35]
Emerging trends in personalised and adaptive learning point to a future where education is increasingly tailored to the learner:

- Greater emphasis on adaptive learning technologies that adjust content based on learner performance and preferences.
- Integration of real-time feedback mechanisms to provide immediate support and guidance to learners.

## 5. Conclusion

### Summary of Key Insights
This survey highlights the transformative potential of MLLMs in education, demonstrating their effectiveness in language learning, STEM education, and content creation. MLLMs have shown significant improvements in learner engagement, comprehension, and overall educational outcomes.

### Final Thoughts[36]
The integration of MLLMs in education represents a significant step forward, offering tools and resources that enhance the learning experience. However, challenges such as ethical considerations and the need for continuous evaluation must be addressed to ensure the responsible use of this technology.

### Call to Action[33]
Further research and development are essential to fully realise the potential of MLLMs in education. Collaboration between educators, technologists, and policymakers will be crucial in shaping the future of education in the age of AI.

## 6. References
Below is a table indicating the papers cited in the survey:

# Research Papers on Multimodal Large Language Models

1.Education(Language/STEM)
2.Medicine/Healthcare
3.Multimodal Language Models
4.Evaluation and Benchmarking
5.Applications and Use Cases
6.Technical Development and Challenges
7.Ethics and Practical Considerations


## Education

| #  | Title                                                                                           | Summary                                                                                                                                                                                                                                                                                                                                                                    |
|----|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1  | Practical and Ethical Challenges of Large Language Models in Education                         | This review discusses the practical and ethical challenges associated with the use of large language models in education. It covers the benefits, potential risks, and considerations for implementation, providing a systematic scoping review of current research and practices.                                                                                               |
| 2  | A Systematic Review of AI Role in the Educational System                                        | This systematic review examines the role of AI in the educational system, based on a proposed conceptual framework. It looks at how AI technologies are being integrated into education, their impacts on teaching and learning, and the challenges associated with their adoption. The review also provides recommendations for educators and policymakers.                        |
| 3  | LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education | The paper discusses LLaVA-Docent, a multimodal large language model designed to enhance art appreciation education through instruction tuning. This model leverages both visual and textual data to provide comprehensive support in understanding and appreciating art.                                                                                                          |
| 4  | Large Language Models in Education: A Focus on the Complementary Relationship Between Human Teachers and ChatGPT | This paper explores the integration of large language models, such as ChatGPT, in educational settings. It emphasizes the complementary relationship between human teachers and AI, highlighting how AI can enhance the teaching process by providing personalized support, automating administrative tasks, and offering new educational resources.                                      |
| 5  | Large Language Models in Education: Vision and Opportunities                                   | This paper presents a vision for the future of education enhanced by large language models. It outlines the opportunities these models offer, such as personalized learning experiences, automated grading, and enriched educational content. The paper discusses the potential impact of AI on various aspects of education, including curriculum development and student engagement.     |
| 6  | On the Application of Large Language Models for Language Teaching and Assessment Technology     | The paper explores the use of large language models in language teaching and assessment. It highlights the benefits of using these models to enhance personalized learning experiences and improve the accuracy of language assessments.                                                                                                                                        |
| 34  | Taking the Next Step with Generative Artificial Intelligence: The Transformative Role of Multimodal Large Language Models in Science Education | This paper explores the transformative role of Multimodal Large Language Models (MLLMs) in science education. It discusses the integration of MLLMs like GPT-4V, capable of processing multimodal data, to enhance teaching and learning. The paper highlights applications in content creation, personalized support, scientific practices, and assessment, while addressing challenges such as data protection and ethical considerations. |
| 37 | Large Multilingual Models Pivot Zero-Shot Multimodal Learning Across Languages | This paper presents MPM, a training paradigm that enables large multimodal models to leverage English multimodal data for training, thus effectively generalizing to other languages with minimal additional data. MPM is validated through the development of VISCPM, a Chinese multimodal model, demonstrating state-of-the-art performance in zero-shot image-to-text and text-to-image tasks. 

## Medicine/Healthcare

| #  | Title                                                                                           | Summary                                                                                                                                                                                                                                                                                                                                                                    |
|----|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 7  | ChatGPT for Shaping the Future of Dentistry                                                     | This article explores how ChatGPT and similar large language models can be utilized in the field of dentistry. It highlights potential applications such as patient education, diagnostic assistance, and administrative tasks, as well as discussing the challenges and ethical considerations associated with their use.                                                        |
| 8  | A Comprehensive Survey of LLM and MLLM in Medicine                                              | A survey of large language models (LLMs) and multimodal language models (MLLMs) in the field of medicine, this document reviews their applications, benefits, and challenges. It discusses how these models can support medical research, diagnostics, and patient care, while also addressing ethical and practical concerns.                                                    |
| 9  | AI and Heart Failure: Present State and Future With Multimodal Large Language Models             | This paper explores the application of AI and multimodal large language models in managing heart failure. It highlights the potential of AI to revolutionize healthcare by integrating large quantities of clinical data and using it for complex decision-making. The paper provides a case study of a patient with heart failure and discusses how AI tools could improve diagnosis and management. |
| 10 | A Comprehensive Survey of LLM and MLLM in Medicine                                              | A survey of large language models (LLMs) and multimodal language models (MLLMs) in the field of medicine, this document reviews their applications, benefits, and challenges. It discusses how these models can support medical research, diagnostics, and patient care, while also addressing ethical and practical concerns.                                                    |
                                                                                       |

## Multimodal Language Models

| #  | Title                                                                                           | Summary                                                                                                                                                                                                                                                                                                                                                                    |
|----|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 11 | Exploring the Potential of Multimodal LLM with Unknown                                          | This paper investigates the potential applications of multimodal large language models (LLMs) across various domains. It examines how these models can be used to enhance the understanding and generation of content involving multiple modalities, such as text, images, and videos.    
| 12 | A Multilingual Language Model with Progressively Enhanced Capabilities                          | InternLM is presented as a multilingual foundational language model with 104B parameters. The document details its training on a large corpus with 1.6T tokens, its evaluation on various benchmarks, and its performance compared to other models like ChatGPT. The model shows strong capabilities in knowledge understanding, reading comprehension, and other tasks.              |
| 13 | A Survey on Multimodal Large Language Models                                                    | This survey focuses on multimodal large language models that integrate text with other types of data such as images and audio. It reviews the state-of-the-art models, their architectures, training methods, and applications. The document also addresses the challenges and potential of these models in handling multimodal information.                                      |
| 14 | SEED-Bench: Benchmarking Multimodal Large Language Models                                       | The paper introduces SEED-Bench, a comprehensive benchmark for evaluating multimodal large language models (MLLMs) across hierarchical capability levels (L0 to L4). SEED-Bench assesses models' abilities to generate and comprehend both text and images through 24K multiple-choice questions spanning 27 dimensions. The benchmark evaluates 22 prominent MLLMs.                |
| 15 | LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to Support Art Appreciation Education | The paper discusses LLaVA-Docent, a multimodal large language model designed to enhance art appreciation education through instruction tuning. This model leverages both visual and textual data to provide comprehensive support in understanding and appreciating art.                                                                                                          |
| 16  | Modularization Empowers Large Language Models with Multimodality | This paper introduces mPLUG-Owl, a novel training paradigm that enhances large language models (LLMs) with multimodal capabilities through modularized learning. It involves a two-stage training scheme that integrates visual knowledge and textual data, demonstrating impressive abilities in multi-modal instruction understanding, visual understanding, multi-turn conversation, and knowledge reasoning. The model outperforms existing multi-modal models and showcases unexpected capabilities like multi-image correlation and scene text understanding. |
| 17 | Exploring the Potential of Multimodal LLM with Unknown                                          | This paper investigates the potential applications of multimodal large language models (LLMs) across various domains. It examines how these models can be used to enhance the understanding and generation of content involving multiple modalities, such as text, images, and videos.                                                                                           |
| 18 | Foundations & Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions | This paper provides an in-depth analysis of multimodal machine learning, discussing its foundational principles, current challenges, and open research questions. It covers the integration of multiple data modalities, such as text, images, and audio, into a unified machine learning framework.                                                                              |
| 19 | Generating Images with Multimodal Language Models                                               | This paper explores the capabilities of multimodal language models in generating images based on textual descriptions. It discusses the underlying mechanisms that allow these models to interpret and visualize textual inputs, producing corresponding images. The study aims to demonstrate the potential of multimodal language models in creative applications, such as digital art. |
| 20 | Generative Multimodal Models are In-Context Learners                                            | This paper examines the concept of generative multimodal models as in-context learners, capable of adapting to new tasks and data without extensive retraining. It discusses how these models can leverage context from multimodal inputs, including text and images, to generate relevant and coherent outputs.                                                                      |
| 35  | Multimodal Classification: Current Landscape, Taxonomy and Future Directions | This paper addresses the challenges in multimodal classification by proposing a new taxonomy for describing multimodal classification models. It reviews the benefits of combining data from multiple sources and the development of novel multimodal architectures. The paper provides examples of applying the taxonomy to existing models, discusses challenges such as big data, class imbalance, and instance-level difficulty, and offers future research directions. |

## Evaluation and Benchmarking

| #  | Title                                                                                           | Summary                                                                                                                                                                                                                                                                                                                                                                    |
|----|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 21 | A Survey on Evaluation of Large Language Models                                                 | This document surveys the methods and metrics used to evaluate large language models. It discusses the importance of proper evaluation to ensure model performance, fairness, and reliability. Various evaluation benchmarks and techniques are reviewed, providing insights into how to assess the effectiveness of these models in different contexts.                                |
| 22 | SEED-Bench: Benchmarking Multimodal Large Language Models                                       | The paper introduces SEED-Bench, a comprehensive benchmark for evaluating multimodal large language models (MLLMs) across hierarchical capability levels (L0 to L4). SEED-Bench assesses models' abilities to generate and comprehend both text and images through 24K multiple-choice questions spanning 27 dimensions. The benchmark evaluates 22 prominent MLLMs.                |
| 23 | A Survey on LLM-Generated Text Detection                                                        | The document surveys techniques and methods for detecting text generated by large language models. It highlights the importance of distinguishing between human-written and machine-generated text for various applications, such as preventing misinformation and ensuring content authenticity. The survey reviews current detection methods and their effectiveness.              |

## Applications and Use Cases

| #  | Title                                                                                           | Summary                                                                                                                                                                                                                                                                                                                                                                    |
|----|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 24 | ChatGPT for Shaping the Future of Dentistry                                                     | This article explores how ChatGPT and similar large language models can be utilized in the field of dentistry. It highlights potential applications such as patient education, diagnostic assistance, and administrative tasks, as well as discussing the challenges and ethical considerations associated with their use.                                                        |
| 25 | How Duolingo Uses AI to Create Lessons Faster                                                   | This article discusses how Duolingo utilizes AI, specifically large language models (LLMs), to accelerate lesson creation and improve course content. Duolingo employs an AI model named "Birdbrain" to tailor exercises to learners' proficiency levels. The use of LLMs allows for the rapid generation of new exercises, which are then reviewed and refined by human experts.      |
| 26 | Generating Images with Multimodal Language Models                                               | This paper explores the capabilities of multimodal language models in generating images based on textual descriptions. It discusses the underlying mechanisms that allow these models to interpret and visualize textual inputs, producing corresponding images. The study aims to demonstrate the potential of multimodal language models in creative applications, such as digital art. |

## Technical Development and Challenges

| #  | Title                                                                                           | Summary                                                                                                                                                                                                                                                                                                                                                                    |
|----|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 27 | A Multilingual Language Model with Progressively Enhanced Capabilities                          | InternLM is presented as a multilingual foundational language model with 104B parameters. The document details its training on a large corpus with 1.6T tokens, its evaluation on various benchmarks, and its performance compared to other models like ChatGPT. The model shows strong capabilities in knowledge understanding, reading comprehension, and other tasks.              |
| 28 | A Survey of Large Language Models                                                               | This survey provides an overview of the development and capabilities of large language models. It covers various models, their architectures, training methods, and applications across different domains. The document also discusses the challenges and limitations faced by these models, as well as future directions for research and development.                                |
| 29 | Bridging Large Language Model Disparities: Skill Tagging of Multilingual                        | This paper discusses methods for bridging disparities in large language models through skill tagging of multilingual data. It explores how these techniques can improve the performance of models in understanding and generating text in multiple languages, addressing issues of bias and fairness.                                                                             |
| 30 | Exploring the Potential of Multimodal LLM with Unknown                                          | This paper investigates the potential applications of multimodal large language models (LLMs) across various domains. It examines how these models can be used to enhance the understanding and generation of content involving multiple modalities, such as text, images, and videos.                                                                                           |
| 31 | Foundations & Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions | This paper provides an in-depth analysis of multimodal machine learning, discussing its foundational principles, current challenges, and open research questions. It covers the integration of multiple data modalities, such as text, images, and audio, into a unified machine learning framework.                                                                              |
| 32 | Generative Multimodal Models are In-Context Learners                                            | This paper examines the concept of generative multimodal models as in-context learners, capable of adapting to new tasks and data without extensive retraining. It discusses how these models can leverage context from multimodal inputs, including text and images, to generate relevant and coherent outputs.                                                                      |
| 36 | Taking the Next Step with MLLM | This paper investigates the advancements in MLLMs and their potential applications in various domains. It highlights the next steps in the development and utilization of these models. 
                                                     |

| 38 | PMG: Personalized Multimodal Generation with Large Language Models  | Introduces PMG, a method for personalized multimodal generation using large language models (LLMs). PMG converts user behaviors into natural language to generate personalized content. |

## Ethics and Practical Considerations

| #  | Title                                                                                           | Summary                                                                                                                                                                                                                                                                                                                                                                    |
|----|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 33 | Practical and Ethical Challenges of Large Language Models in Education                         | This review discusses the practical and ethical challenges associated with the use of large language models in education. It covers the benefits, potential risks, and considerations for implementation, providing a systematic scoping review of current research and practices.                                                                                               |                                                 |
